# Анализ требований и подготовка архитектурного решения

**Цель:** В этом домашнем задании вы проведёте анализ требований и предложите архитектурное решение.


**Кейс:** (Собственный) Созднание BI-платформы для автоматизации доставки данных до Stage-слоя DWH. 


## 0. Бизнес-контекст

BI-департамент подготавливает витрины данных для коллег из смежных департаментов. Источниками данных для витрин являются компоненты продуктовых команд компании, в качестве основного транспорта выступает Kafka.

Типовой сценарий - просмотр целевых показателей в дашборде после запуска нового проекта.  

Данные для витрин хранятся в DWH на реляционной СУБД. DWH разбито на слои (Stage -> Operational Data Store -> Common Data Mart -> Product Data Mart).

Для разработки новой витрины может потребоваться разбор нового топика или добавление новых полей в существующий топик, с организацией проброса данных по слоям посредством ETL-процессов. 

Т.к. в свое время было проведено разделение компонентов на "микросервисы", этот процесс может затянуться из-за большого количества рутинных действий со стороны разработчиков в нескольких репозиториях. Добавляем к этому вероятность человеческих ошибок, ревью, тестирование и прочие накладные расходы.

Поток данных довольно большой, при этом важна полнота - нельзя потерять ни одной транзакции.


## 1. Бизнес-цели и бизнес-драйверы

**Бизнес-цель:** Разработать BI-платформу для автоматизации и унификации механизма загрузки данных в Stage слой DWH. Тем самым, сократить Time To Market для появления данных в витринах.

**Бизнес-драйверы:**
* В настоящее время задачи по разбору нового топика в Stage-слой DWH могут выполняться до 4-х недель, заказчики жалуются на сроки

* Т.к. на этапе загрузки в Stage отсутствует какая-либо бизнес логика, задачи превращаются в copy-paste, что приводит к риску возникновения человеческих ошибок, которые тяжело выявить во время ревью кода.

* За счет большого количества ручных операций, скорость выполнения задач невозможно увеличить через повышение квалификации разработчиков

* Даже в минимальной по сложности задаче нужно организовать 3-4 релиза для раскатки изменений по всем задействованным в процессе компонентам. 


## 2. Стейкхолдеры и их потребности

* **Руководитель BI-департамента** - заинтересован в развитии BI-инструментов и их востребованности в ландшафте компании

* **Разработчики BI-департамента (разработчики)** - хотят избавиться от рутинных однотипных задач и тратить время на что-то более интересное и сложное

* **Тестировщики** - заинтересованы в автоматизации тестирования задач BI-департамента 

## 3. Пользовательские истории

**UC-1:** Просмотр актуального состояния разбора топиков

Разработчик получает информацию от разбираемых в настоящее время топиков Kafka.

**UC-2:** Разбор нового топика

Разработчик запускает разбор данных из топика в реляционные таблицы Stage-слоя БД в соответствии с его спецификацией.

**UC-3:** Изменение набора разбираемых атрибутов

Разработчик инициирует модификацию структуры таблиц БД и кода для разбора сообщений из топика Kafka. 

**UC-4:** Архивирование исходных сообщений топика

Разработчик создает объекты в БД для архивирования данных, готовит конфигурацию для ETL-процесса архивации

**UC-5:** Ревью задач по разбору топиков

Разработчик создает PR и вмердживает свои изменения в кодовую базу после получения апрува от коллег

**UC-6:** Тестирование разбора топика на синтетических данных

Разработчик готовит код producer'а для отправки тестовых данных в Kafka.
Тестировщик генерирует синтетические данные и проверяет работу механизма загрузки 

**UC-7:** Нотификация об ошибках при разборе

Разработчик получает уведомление о появлении ошибок в процессе разбора сообщений из топика Kafka 

**UC-8:** Остановка разбора топика

Разработчик останавливает разбор сообщений из указанного топика

**UC-9:** Запуск приостановленного разбора топика

Разработчик запускает ранее приостановленный разбор сообщений из указанного топика


## 4. Атрибуты качества (и не функциональные требования)

* Программный код для разора топиков генерируется автоматически на основе спецификации топика

* Структура объектов БД создается и модифицируется автоматически, на основе спецификации топика

* Разработчик должен иметь доступ к просмотру текущего состояния разбора и истории изменении его статусов

* В качестве источника метаданных для кодогенерации должны использоваться спецификации топиков Kafka в формате OpenAPI

* Lead Time при использовании Платформы должно быть минимум в 5 раз меньше, чем в предыдущем "ручном" сценарии

* Платформа должна успешно обрабатывать совокупый поток в 50 млн. сообшений в сутки.

* Все исходные сообщения из топика должны быть сохранены в БД, нельзя терять ни одной записи

**Нефункциональные требования:**

* Возможность масштабирования

* Кроссплатформенность

## 5. Контекстная схема системы

### C1

![C1](img/С1.png?raw=true "C1")

### C2

![C2](img/C2.png?raw=true "C2")

## 6. Критические сценарии и критические характеристики

**Критические сценарии:**
* Разработчик запускает разбор данных из топика в реляционные таблицы Stage-слоя БД в соответствии с его спецификацией

*  Разработчик инициирует модификацию структуры таблиц БД и кода для разбора сообщений из топика Kafka

**Критичные характеристики:**
* **Надежность** - Все исходные сообщения из топика должны быть сохранены в БД, нельзя терять ни одной записи

* **Производительность** - Платформа должна успешно обрабатывать совокупый поток в 50 млн. сообшений в сутки

* **Эффективность** - Lead Time при использовании Платформы должно быть минимум в 5 раз меньше, чем в предыдущем "ручном" сценарии

## 7. Архитектурные решения

### ADR-01

**1. Контекст проблемы, которую решаем**

За основу для кодогенерации берется спецификация топика в OpenAPI. Необходимо определить формат хранения спецификации в конфигурационной таблицы Платформы

**2. Возможные альтернативы решения**

Хранить в оригинальном формате OpenAPI, преобразовывать во внутренний формат

**3. Решение**

За последний год формат спецификаций успел поменяться несколько раз, даже в рамках OpenAPI есть простор для творчества. Поэтому решено проводить преобразование исходной спецификации во внутреннее представление, которое будет использоваться в Платформе. 

**4. Последствия решения**

Решение позволит избежать необходимости массовых доработок в разных сервисах системы при изменении формата спецификации.

**5. Риски, сильные стороны, компромиссы и т.д**

**Риски**
- несовместимость форматов - удаление из исходного формата спецификаций критически важных элементов 

**Сильные стороны**
- независимость от изменений исходного формата во внутренних сервисах системы


### ADR-02

**1. Контекст проблемы, которую решаем**

Разбор сообщений топиков Kafka - типовая задача. Нужно выбрать инструмент.

**2. Возможные альтернативы решения**

Kafka Connect, самописный сервис на C# с использованием оригинальных готовых библиотек от вендора,  поиск Open Source инструментов

**3. Решение**

Исходя из того, что у команды разработки уже был реализован самописный consumer-сервис для чтения сообщений и его можно в сжатые сроки адоптировать под новые требования, решили остановиться именно на этом варианте.   

**4. Последствия решения**

Команда полностью контролирует процесс и может делать доработки при необходимости.

**5. Риски, сильные стороны, компромиссы и т.д**

**Риски**
- Самописное решение может уступать по качеству продуктам на рынке

**Сильные стороны**
- Скорость внедрения
- Экспертиза внутри команды
- Возможность доработок при необходимости